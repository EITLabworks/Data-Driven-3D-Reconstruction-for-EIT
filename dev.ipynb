{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904782cf-a8b0-46b5-ad24-8d904a0c30e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.classes import BallAnomaly, Boundary\n",
    "from src.util import plot_voxel, voxel_ball\n",
    "\n",
    "boundary = Boundary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f4420-fe82-435b-b2cd-0b055d11973e",
   "metadata": {},
   "source": [
    "Diameter\n",
    "\n",
    "- 30mm $\\rightarrow$ `d= 5`\n",
    "- 20mm $\\rightarrow$ `d= 4`\n",
    "- 10mm $\\rightarrow$ `d= 3`\n",
    "\n",
    "Material\n",
    "\n",
    "- acrylic $\\rightarrow$ $\\gamma$ = 1\n",
    "- metal $\\rightarrow$ $\\gamma$ = 2\n",
    "\n",
    "Literature\n",
    "\n",
    "- [Variational Autoencoder (VAE) with Discrete Distribution using Gumbel Softmax](https://towardsdatascience.com/variational-autoencoder-vae-with-discrete-distribution-using-gumbel-softmax-b3f749b3417e)\n",
    "\n",
    "- [Tutorial: Categorical Variational Autoencoders using Gumbel-Softmax](https://blog.evjang.com/2016/11/tutorial-categorical-variational.html)\n",
    "\n",
    "- [Categorical Reparameterization with Gumbel-Softmax](https://github.com/EderSantana/gumbel)\n",
    "    - [GitHub Categorical Reparameterization with Gumbel-Softmax](https://github.com/ericjang/gumbel-softmax/blob/master/Categorical%20VAE.ipynb)\n",
    "\n",
    "\n",
    "- [CAT VAE](https://github.com/flatironinstitute/catvae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f1297f-d853-4da3-9c37-7d44377c4ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ball = BallAnomaly(x=10, y=10, z=10, r=5, γ=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c4e4d-0a9e-4958-8944-7badc77887b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ball_vxl = voxel_ball(ball, boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f3889-7a24-4a13-985e-8517d03a450b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_voxel(ball_vxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c81267-21de-4543-8216-03ca5fb3e26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all combinations:\n",
    "2 * 3 * 18 * 18 * 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6f1fa-b4d7-4241-935c-aa9650edc0d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_all_anomalys = list()\n",
    "\n",
    "for γ in [1, 2]:  #  acrylic, metal\n",
    "    for r in [3, 4, 5]:  # diameter\n",
    "        for x in np.arange(boundary.x_0 + ball.r, boundary.x_length - ball.r, 2):\n",
    "            for y in np.arange(boundary.y_0 + ball.r, boundary.y_length - ball.r, 2):\n",
    "                for z in np.arange(\n",
    "                    boundary.z_0 + ball.r, boundary.z_length - ball.r, 2\n",
    "                ):\n",
    "                    ball = BallAnomaly(x, y, z, r, γ)\n",
    "                    X_all_anomalys.append(voxel_ball(ball, boundary))\n",
    "\n",
    "X_all_anomalys = np.array(X_all_anomalys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379e8b0-516e-4687-b4ed-c45d583713ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_all_anomalys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dafa59-36e6-452a-b899-62e5c0e989bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rdn in np.random.randint(low=0, high=X_all_anomalys.shape[0], size=5):\n",
    "    plot_voxel(X_all_anomalys[rdn, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5216bc92-dffb-423b-83f8-bb5cd23f4fda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.backend import random_normal\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Conv3D,\n",
    "    Conv3DTranspose,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Layer,\n",
    "    Reshape,\n",
    ")\n",
    "from tensorflow.keras.losses import (\n",
    "    binary_crossentropy,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    ")\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "filters = [1, 2, 4, 8]\n",
    "kernels = [(4, 4, 4), (4, 4, 4), (4, 4, 4), (4, 4, 4)]\n",
    "strides = [(1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2)]\n",
    "paddings = [\"same\", \"same\", \"same\", \"same\"]\n",
    "\n",
    "latent_dim = 8\n",
    "\n",
    "\n",
    "class Sampling(Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, beta=1.0, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.total_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            kl_loss = 1 + z_log_var - tf.pow(z_mean, 2) - tf.exp(z_log_var)\n",
    "            kl_loss = -0.5 * tf.reduce_sum(kl_loss, axis=-1)\n",
    "            reconstruction_loss = binary_crossentropy(\n",
    "                data, reconstruction, axis=(1, 2, 3)\n",
    "            )  #\n",
    "            reconstruction_loss *= np.prod((32, 32, 32, 1))\n",
    "            # β-VAE\n",
    "            # print(\"beta value:\",self.beta)\n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(VAE, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"encoder\": tf.keras.utils.serialize_keras_object(self.encoder),\n",
    "                \"decoder\": tf.keras.utils.serialize_keras_object(self.decoder),\n",
    "                \"beta\": self.beta,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "def encoder_model(\n",
    "    input_shape=(32, 32, 32, 1),\n",
    "    filters=filters,\n",
    "    kernels=kernels,\n",
    "    strides=strides,\n",
    "    paddings=paddings,\n",
    "    latent_dim=latent_dim,\n",
    "):\n",
    "    encoder_inputs = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(encoder_inputs)\n",
    "\n",
    "    for fltr, krnl, strd, pddng in zip(filters, kernels, strides, paddings):\n",
    "        x = Conv3D(\n",
    "            filters=fltr,\n",
    "            kernel_size=krnl,\n",
    "            strides=strd,\n",
    "            padding=pddng,\n",
    "            activation=\"elu\",\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    z_mean = Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()((z_mean, z_log_var))\n",
    "\n",
    "    return encoder_inputs, z_mean, z_log_var, z\n",
    "\n",
    "\n",
    "def decoder_model(\n",
    "    input_shape=(32, 32, 32, 1),\n",
    "    filters=filters[::-1],\n",
    "    kernels=kernels[::-1],\n",
    "    strides=strides[::-1],\n",
    "    paddings=paddings[::-1],\n",
    "    latent_dim=latent_dim,\n",
    "):\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = Dense(512, activation=\"relu\")(latent_inputs)\n",
    "    x = Reshape((4, 4, 4, 8))(x)\n",
    "\n",
    "    for fltr, krnl, strd, pddng in zip(filters, kernels, strides, paddings):\n",
    "        x = Conv3DTranspose(\n",
    "            filters=fltr,\n",
    "            kernel_size=krnl,\n",
    "            strides=strd,\n",
    "            padding=pddng,\n",
    "            activation=\"elu\",\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    decoded = x\n",
    "\n",
    "    return latent_inputs, decoded\n",
    "\n",
    "\n",
    "def vae_model(\n",
    "    input_shape=(32, 32, 32, 1),\n",
    "    filters=filters,\n",
    "    kernels=kernels,\n",
    "    strides=strides,\n",
    "    paddings=paddings,\n",
    "    latent_dim=latent_dim,\n",
    "    beta=1.0,\n",
    "):\n",
    "    encoder_inputs, z_mean, z_log_var, z = encoder_model(\n",
    "        input_shape=(32, 32, 32, 1),\n",
    "        filters=filters,\n",
    "        kernels=kernels,\n",
    "        strides=strides,\n",
    "        paddings=paddings,\n",
    "        latent_dim=latent_dim,\n",
    "    )\n",
    "    encoder = Model(encoder_inputs, (z_mean, z_log_var, z), name=\"VAE_encoder\")\n",
    "\n",
    "    decoder_inputs, decoder_outputs = decoder_model(\n",
    "        input_shape=(32, 32, 32, 1),\n",
    "        filters=filters[::-1],\n",
    "        kernels=kernels[::-1],\n",
    "        strides=strides[::-1],\n",
    "        paddings=paddings[::-1],\n",
    "        latent_dim=latent_dim,\n",
    "    )\n",
    "    decoder = Model(decoder_inputs, decoder_outputs, name=\"VAE_decoder\")\n",
    "\n",
    "    return VAE(encoder, decoder, beta=beta)\n",
    "\n",
    "\n",
    "# engineering decoder and encoder parts:\n",
    "\n",
    "encoder_inputs, z_mean, z_log_var, z = encoder_model(\n",
    "    input_shape=(32, 32, 32, 1),\n",
    "    filters=filters,\n",
    "    kernels=kernels,\n",
    "    strides=strides,\n",
    "    paddings=paddings,\n",
    "    latent_dim=latent_dim,\n",
    ")\n",
    "encoder = Model(encoder_inputs, (z_mean, z_log_var, z), name=\"VAE_encoder\")\n",
    "\n",
    "decoder_inputs, decoder_outputs = decoder_model(\n",
    "    input_shape=(32, 32, 32, 1),\n",
    "    filters=filters[::-1],\n",
    "    kernels=kernels[::-1],\n",
    "    strides=strides[::-1],\n",
    "    paddings=paddings[::-1],\n",
    "    latent_dim=latent_dim,\n",
    ")\n",
    "decoder = Model(decoder_inputs, decoder_outputs, name=\"VAE_decoder\")\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c696c60-a70b-4b3e-b12a-5bea465b2170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.expand_dims(X_all_anomalys, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf638ee-bb97-4fa4-9cc5-0bdd59a2e359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae = vae_model(input_shape=(32, 32, 32, 1), beta=1.05)\n",
    "vae.compile(optimizer=Adam())\n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "\n",
    "cb = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=0, start_from_epoch=470)\n",
    "\n",
    "history = vae.fit(\n",
    "    np.expand_dims(X_all_anomalys, 4),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[cb],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
