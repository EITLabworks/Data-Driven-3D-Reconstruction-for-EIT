{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237d7ab2-a1f6-4b7e-9e4c-8ca17f9cb03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.datagenerator import DataGenerator, DataLoader, z_score\n",
    "from src.performance_evaluation import (\n",
    "    compute_PCA,\n",
    "    compute_position_error,\n",
    "    compute_volume_error,\n",
    "    plot_confusion_matrix,\n",
    "    plot_PCA,\n",
    ")\n",
    "from src.util import plot_voxel\n",
    "\n",
    "# load vae model\n",
    "from src.vae import vae_model\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8521bd8-fdfd-47c4-9c0b-cf63cc08a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f729a-1865-4a1d-99ea-df8b8ddd1ba6",
   "metadata": {},
   "source": [
    "# Stage 2\n",
    "\n",
    "**1. Training of the material classificator $\\Upsilon$**\n",
    "\n",
    "**2. Training of the mapper $\\Xi$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb0537-8881-4d4d-9cf6-3ab3cd394e72",
   "metadata": {},
   "source": [
    "## Material classificator $\\Upsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2e5cb6-4748-429c-9606-a95933df23e8",
   "metadata": {},
   "source": [
    "**CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3327408-a236-426d-8c84-9a8358aa7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagenerator = False\n",
    "\n",
    "params = {\n",
    "    \"path\": \"../3dIT/measurements/datapool/\",\n",
    "    \"mean_path\": \"../3dIT/measurements/datameans/\",\n",
    "    \"eit_dim\": 4096,\n",
    "    \"supervised\": \"material\",  # \"diameter\", \"material\", \"anomaly\", \"anomaly_and_material\"\n",
    "    \"batch_size\": 16,\n",
    "    \"shuffle\": True,\n",
    "    \"EIT_shape\": \"matrix\",\n",
    "}\n",
    "\n",
    "if datagenerator:\n",
    "    idx = np.arange(0, len(os.listdir(params[\"path\"])))\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    limit_index = 100_000\n",
    "\n",
    "    training_generator = DataGenerator(idx[:limit_index], **params)\n",
    "    test_____generator = DataGenerator(idx[limit_index:], **params)\n",
    "    X, Y = training_generator[0]\n",
    "else:\n",
    "    X, Y = DataLoader(params)\n",
    "    X = z_score(X)\n",
    "    X = np.expand_dims(X, axis=3)\n",
    "    print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab2bf5-1eb4-4d48-8b45-b4b7b74b52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345fbfdf-f5e8-4e99-afb6-d134f12a5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d2bd6-5e57-4333-a5cc-11a6626e76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca = compute_PCA(X_train)\n",
    "plot_PCA(data_pca, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa8d92-78ba-4fd4-8dbe-e66927dc94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca = compute_PCA(X_test)\n",
    "plot_PCA(data_pca, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109f62b4-0f05-4011-b7ad-59ba282caba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4412504e-425d-43ba-83fe-da520f24b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def material_classificator(input_shape=(64, 64, 1), m_dim=1, kernel=3):\n",
    "    mapper_input = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(8, kernel, strides=(2, 4), padding=\"same\")(mapper_input)\n",
    "    x = tf.keras.layers.Conv2D(16, kernel, strides=(2, 4), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(16)(x)\n",
    "    mapper_output = tf.keras.layers.Dense(m_dim, activation=\"sigmoid\")(x)\n",
    "    return tf.keras.Model(mapper_input, mapper_output)\n",
    "\n",
    "\n",
    "material_classificator_CNN = material_classificator()\n",
    "material_classificator_CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed29e2-295b-45da-8eda-49a190260f0d",
   "metadata": {},
   "source": [
    "It is possible to insert the `softmax` function into the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it's impossible to provide an exact and numerically stable loss calculation for all models when using a softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887090e9-61be-48b4-908c-2731a1430e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy\n",
    "material_classificator_CNN.compile(\n",
    "    tf.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfc13b-321e-4ed3-8767-450d30699371",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator_history_CNN = material_classificator_CNN.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=20,\n",
    "    batch_size=params[\"batch_size\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d993aa-4f13-4913-8f82-c2a67e5a1958",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(classificator_history_CNN.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dad670-a739-41f7-bdd4-3c198f90d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "material_classificator_CNN.save_weights(\"models/material_mapper.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417393d5-4003-46b3-a8e5-625f5740ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.concatenate(np.round(material_classificator_CNN.predict(X_test)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53ab9876-8832-4bb9-9d58-1be759b87183",
   "metadata": {},
   "source": [
    "m_i = len(glob.glob(\"models/mapper_*\"))\n",
    "s_path = f\"models/mapper_{m_i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d45b7d-bd82-43a7-853f-5e521a3b45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839245ca-c045-4120-86cc-259f4844c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(s_path)\n",
    "# material_classificator_CNN.save(f\"{s_path}/model.keras\")\n",
    "# np.savez(s_path + \"/test_data.npz\", X_test=X_test, Y_test=Y_test, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71131b2-9fd0-4b86-834a-232d845ac945",
   "metadata": {},
   "source": [
    "## Mapper $\\Xi$\n",
    "\n",
    "Loat the VAE model and train the two required mapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a9a3f-4c6a-4c05-9146-30d74e7d8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = vae_model()\n",
    "vae.load_weights(\"models/vaes/vae_21.weights.h5\")\n",
    "vae.summary()\n",
    "\n",
    "Φ = vae.encoder\n",
    "Ψ = vae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea066be-6bc4-4812-b98b-94e5782a1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"path\": \"../3dIT/measurements/datapool/\",\n",
    "    \"mean_path\": \"../3dIT/measurements/datameans/\",\n",
    "    \"eit_dim\": 4096,\n",
    "    \"EIT_shape\": \"matrix\",\n",
    "    \"supervised\": \"anomaly_and_material\",  # \"diameter\", \"material\", \"anomaly\", \"anomaly_and_material\"\n",
    "    \"batch_size\": 128,\n",
    "    \"shuffle\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1182b8-7c5f-448b-8190-8a17ed0091f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, m = DataLoader(params)\n",
    "\n",
    "X = z_score(X)\n",
    "X = np.expand_dims(X, axis=3)\n",
    "Y = np.expand_dims(Y, axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a797af9b-101b-4eaa-8f55-8ef49c9575d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, gamma_train, gamma_test, m_train, m_test = train_test_split(\n",
    "    X, Y, m, test_size=0.1, random_state=42\n",
    ")\n",
    "# del X,Y,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535113eb-6c52-420f-937b-7cb8deb7ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, z_train = Φ.predict(gamma_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca1ff0-78f0-403f-85f6-7b142b7fdbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, z_test = Φ.predict(gamma_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "645f0c61-ba3d-4677-a358-28aa6b782bcc",
   "metadata": {},
   "source": [
    "np.savez(\"models/testdata_stage3.npz\",\n",
    "        X_test = X_test,\n",
    "        gamma_test = gamma_test,\n",
    "        m_test=m_test,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df33ca-4501-4560-b4fd-1bf8c9ece236",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, gamma_train.shape, m_train.shape, z_train.shape)\n",
    "print(X_test.shape, gamma_test.shape, m_test.shape, z_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dcc17c-2c13-4ec4-90d1-5ce60093ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.load(\"models/mappers/predictable_model_10.npz\", allow_pickle=True)\n",
    "print(f\"{tmp['precision']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a82567-d368-4ca3-92ad-e2844ae60da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |---------------------- HPT#1 --------------------- with VAE model = 17-------------------------------------------------------------|\n",
    "# | model  a1: e = 50 , bs = 16, filters=[2,  4,  8, 16], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=55.06 %|\n",
    "# | model  a2: e = 75 , bs = 16, filters=[4,  8, 16, 32], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=50.93 %|\n",
    "# | model  a3: e = 75 , bs = 16, filters=[4,  8,  8, 16], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=56.12 %|\n",
    "# | model  a4: e = 75 , bs = 16, filters=[8,  8,  8, 16], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=61.84 %|\n",
    "# | model  a5: e = 75 , bs = 16, filters=[8, 16, 32, 64], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=58.16 %|\n",
    "\n",
    "# | model  a6: e = 75 , bs =  8, filters=[8, 16, 32, 64], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=77.92 %|\n",
    "# | model  a7: e = 75 , bs =  8, filters=[8, 16, 32, 64], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=67.13 %|\n",
    "# | model  a8: e = 75 , bs =  8, filters=[8, 16, 32, 64], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=64.90 %|\n",
    "# | model  a9: e = 75 , bs =  8, filters=[8, 16, 32, 64], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mae, predictable=62.13 %|\n",
    "# | model a10: e = 75 , bs =  4, filters=[8, 16, 32, 64], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mae, predictable=55.17 %|\n",
    "# |-----------------------------------------------------------------------------------------------------------------------------------|\n",
    "\n",
    "# Changed the VAE because of the discovery of a better generalized version.\n",
    "# ... continue with the best prediction performance of HPT#1 -> model configuration 6.\n",
    "\n",
    "# |--------------------- HPT#2 -----------------------with VAE model = 21-------------------------------------------------------------|\n",
    "# | model  1: e = 75 , bs =  8, filters=[ 8, 16, 32, 64], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=92.19 %|\n",
    "# | model  2: e = 75 , bs =  6, filters=[ 8, 16, 32, 64], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=90.94 %|\n",
    "# | model  3: e = 75 , bs =  8, filters=[16, 32, 32, 64], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=92.09 %|\n",
    "# | model  4: e = 75 , bs =  8, filters=[8, 32, 64, 128], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable=92.77 %|\n",
    "# | model  5: e = 75 , bs =  8, filters=[8, 32, 64, 128], kernels(2, 2), strides=(1, 1), pools=(2, 2), loss = mse, predictable=54.65 %|\n",
    "\n",
    "# | model  6: e = 75 , bs =  8, filters=[4, 8, 16, 32], kernels(2, 2), strides=(1, 1), pools=(2, 2), loss = mse, predictable = 92.54 %|\n",
    "# | model  7: e = 75 , bs =  6, filters=[4, 8, 16, 32], kernels(4, 4), strides=(1, 1), pools=(2, 2), loss = mse, predictable = 92.58 %|\n",
    "# | model  8: e = 75 , bs =  5, filters=[4, 8, 16, 32], kernels(4, 4), strides=(1, 1), pools=(2, 2), loss = mse, predictable = 96.01 %|\n",
    "# | model  9: e = 75 , bs =  16,filters=[4, 8, 16, 32], kernels(4, 4), strides=(1, 1), pools=(2, 2), loss = mse, predictable = 90.83 %|\n",
    "# | model 10: e = 75 , bs =  5, filters=[4, 8, 16, 32], kernels(3, 3), strides=(1, 1), pools=(2, 2), loss = mse, predictable = 90.06 %|\n",
    "# |-----------------------------------------------------------------------------------------------------------------------------------|\n",
    "\n",
    "epochs = 75\n",
    "batch_size = 5\n",
    "\n",
    "\n",
    "def mapper_CNN(input_shape=(64, 64, 1), latent_dim=8):\n",
    "    filters = [4, 8, 16, 32]\n",
    "    kernels = [(3, 3) for _ in range(4)]\n",
    "    strides = [(1, 1) for _ in range(4)]\n",
    "    pools = [(2, 2) for _ in range(4)]\n",
    "\n",
    "    print(f\"{filters=}, kernels{kernels[0]}, strides={strides[0]}, pools={pools[0]}\")\n",
    "\n",
    "    x = tf.keras.layers.Input(shape=input_shape)\n",
    "    mapper_input = x\n",
    "\n",
    "    for f, k, s, p in zip(filters, kernels, strides, pools):\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters=f, kernel_size=k, strides=s, padding=\"valid\", activation=\"relu\"\n",
    "        )(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=p)(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(latent_dim, activation=\"relu\")(x)\n",
    "    mapper_output = tf.keras.layers.Dense(latent_dim)(x)\n",
    "\n",
    "    return tf.keras.Model(mapper_input, mapper_output)\n",
    "\n",
    "\n",
    "Ξ = mapper_CNN()\n",
    "# losses to try:\n",
    "# mean_squared_logarithmic_error\n",
    "# mean_absolute_percentage_error\n",
    "Ξ.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=\"mse\")\n",
    "Ξ.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61824995-30e5-48f3-9dea-8927534000b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"{batch_size=}, {epochs=}\")\n",
    "history = Ξ.fit(X_train, z_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a103a80-6159-42a0-9c98-5753535e21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=keys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5906f-d156-4915-9ffc-bb2d47be099d",
   "metadata": {},
   "source": [
    "**Test the mapper $\\Xi$ performance**\n",
    "\n",
    "The variable `γ_hat` represents $\\hat{\\gamma}$, which is the reconstructed conductivity distribution.\n",
    "It is generated by:\n",
    "$$\\hat{\\gamma} = \\Psi(\\Xi(\\mathbf{u})) = \\Psi \\circ \\Xi :  \\mathbf{u} \\mapsto \\mathbf{z} \\mapsto \\hat{\\gamma} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7405d3f-de5f-452d-a507-47b8007b5673",
   "metadata": {},
   "outputs": [],
   "source": [
    "γ_hat = Ψ.predict(Ξ.predict(X_test))\n",
    "γ_hat = np.squeeze(γ_hat, axis=4)\n",
    "γ_hat = np.clip(γ_hat, a_min=0, a_max=1)\n",
    "γ_hat[γ_hat != 0] = 1\n",
    "print(γ_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836c0bf-fde8-4e84-b689-a9f1a9d58ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"default\")\n",
    "for rdn in np.random.randint(low=0, high=γ_hat.shape[0], size=5):\n",
    "    print(\"True γ distribution\")\n",
    "    plot_voxel(gamma_test[rdn, :, :, :, 0])\n",
    "    print(\"Predicted γ distribution\")\n",
    "    plot_voxel(γ_hat[rdn])\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265eb1b5-6786-4655-96e2-1b31bb4785a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_idx = len(glob.glob(\"models/mappers/*.h5\")) + 1\n",
    "mapper_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093b75c-b475-4ec1-b81c-8a4e46698016",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_measure = dict(Model=list(), Error_val=list(), Error=list(), test_idx=list())\n",
    "\n",
    "data_append = []\n",
    "\n",
    "for idx, v_err in enumerate(compute_volume_error(γ_hat, gamma_test)):\n",
    "    if v_err != None:\n",
    "        v_percent = (v_err / 32**3) * 100\n",
    "        data_append.append(\n",
    "            dict(Model=mapper_idx, Error_val=v_percent, Error=\"Volume\", test_idx=idx)\n",
    "        )\n",
    "\n",
    "for idx, p_err in enumerate(compute_position_error(gamma_test, γ_hat)):\n",
    "    if p_err != None:\n",
    "        p_percent = (p_err / np.linalg.norm(np.array([32, 32, 32]))) * 100\n",
    "        data_append.append(\n",
    "            dict(Model=mapper_idx, Error_val=p_percent, Error=\"Position\", test_idx=idx)\n",
    "        )\n",
    "\n",
    "# Create dictionary\n",
    "for item in data_append:\n",
    "    for key, value in item.items():\n",
    "        acc_measure[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b42add-11fd-40bd-8edf-dfa55b63dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_measure_df = pd.DataFrame(acc_measure).dropna()\n",
    "acc_measure_df.to_csv(\n",
    "    f\"models/mappers/mappers_acc_measure_{mapper_idx}.csv\", index=False\n",
    ")\n",
    "acc_measure_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d723ef6-6e0b-4075-892d-b7d011e729fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)\n",
    "sns.set_context(context=\"paper\", font_scale=1.4)\n",
    "custom_palette = [\"#756bb1\", \"#a1d99b\"]\n",
    "sns.boxplot(\n",
    "    x=\"Model\",\n",
    "    y=\"Error_val\",\n",
    "    data=acc_measure_df,\n",
    "    hue=\"Error\",\n",
    "    showfliers=True,\n",
    "    palette=custom_palette,\n",
    ")  #  violinplot: , split=True\n",
    "plt.ylabel(\"Error (%)\")\n",
    "# plt.xlabel(\"Model Iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5108dfc-f2e9-4927-a9e9-464bb4380916",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ξ.save_weights(f\"models/mappers/mapper_{mapper_idx}.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a403d-c14b-4efa-8d38-95fc3b6b2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK HOW MUCH TEST DATA CAN (NOT) BE PREDICTED!\n",
    "volume_preds = len([True for ele in acc_measure_df[\"Error\"] if ele == \"Volume\"])\n",
    "position_preds = len([True for ele in acc_measure_df[\"Error\"] if ele == \"Position\"])\n",
    "print(\"Length condition is:\", np.allclose(volume_preds, position_preds))\n",
    "precision = volume_preds / gamma_test.shape[0] * 100\n",
    "print(f\"Copy this to the top hpt entry:\\n {precision:.2f}%\")\n",
    "np.savez(\n",
    "    f\"models/mappers/predictable_model_{mapper_idx}.npz\",\n",
    "    precision=precision,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a80d5c-57db-4118-be37-1b5764a7a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files and concatenate them\n",
    "# plt.style.use('default')\n",
    "\n",
    "combined_df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(f_csvs)\n",
    "        for f_csvs in glob.glob(\"models/mappers/mappers_acc_measure_*.csv\")\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "combined_df = pd.DataFrame(combined_df)\n",
    "# combined_df.to_csv(f\"models/mappers/all_measures.csv\", index=False)\n",
    "custom_palette = [\"#756bb1\", \"#a1d99b\"]\n",
    "sns.boxplot(\n",
    "    x=\"Model\",\n",
    "    y=\"Error_val\",\n",
    "    data=combined_df,\n",
    "    hue=\"Error\",\n",
    "    showfliers=True,\n",
    "    palette=custom_palette,\n",
    ")  #  violinplot: , split=True\n",
    "plt.ylabel(\"Error (%)\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/vae_hpt.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7571f045-a76b-4bc3-bbea-7c00fd863e34",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
