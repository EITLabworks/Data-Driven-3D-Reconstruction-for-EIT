{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a873ae20-8717-4085-96d4-70f433cf0a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 10:14:24.555552: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 10:14:34.485071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from src.util import plot_voxel\n",
    "\n",
    "# import vae\n",
    "from src.vae import vae_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c4a6b-be3c-4c87-a71a-c7e5d2993a40",
   "metadata": {},
   "source": [
    "# Stage 3\n",
    "\n",
    "_Build the full reconstruction network architecture_\n",
    "\n",
    "1. Load the VAE $\\Psi : \\mathbf{z} \\mapsto \\hat{\\gamma}$\n",
    "2. Load the mapper $\\Xi : \\mathbf{u} \\mapsto \\mathbf{z}$\n",
    "3. Load the material classificator $\\Upsilon : \\mathbf{u} \\mapsto \\mathbf{m}$\n",
    "\n",
    "The final model is described by:\n",
    "\n",
    "$$\\Gamma := \\Xi \\circ \\Psi : \\mathbf{u} \\mapsto \\mathbf{z} \\mapsto \\hat{\\gamma} $$\n",
    "\n",
    "with the material classification model:\n",
    "\n",
    "$$\\Upsilon : \\mathbf{u} \\mapsto \\mathbf{m} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199db893-58f6-4245-8d18-d09af9d66885",
   "metadata": {},
   "source": [
    "## *i)* Load the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea755be-a4cf-43e8-9afc-80cac8017c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 12:30:07.187787: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vae\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"vae\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ VAE_encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,935</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ VAE_decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,419</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ VAE_encoder (\u001b[38;5;33mFunctional\u001b[0m)        │ ?                      │         \u001b[38;5;34m6,935\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ VAE_decoder (\u001b[38;5;33mFunctional\u001b[0m)        │ ?                      │         \u001b[38;5;34m9,419\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,354</span> (63.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,354\u001b[0m (63.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,292</span> (63.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,292\u001b[0m (63.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> (248.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m62\u001b[0m (248.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae = vae_model()\n",
    "vae.load_weights(\"models/vae.weights.h5\")\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab6e0b9-069f-4d3b-8ca9-55e95ef9deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073, 32, 32, 32) (2073,)\n"
     ]
    }
   ],
   "source": [
    "tmp = np.load(\"models/vae_testdata.npz\", allow_pickle=True)\n",
    "X_test, r_test = tmp[\"X_test\"], tmp[\"r_test\"]\n",
    "print(X_test.shape, r_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b5c64cd-3438-4535-bf1d-5ac29c8551da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step\n"
     ]
    }
   ],
   "source": [
    "_, _, z_pred = vae.encoder.predict(X_test)\n",
    "gamma_pred = vae.decoder.predict(z_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad448d-3875-4978-ae1a-d0bfbe0de2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rdn in np.random.randint(low=0, high=X_test.shape[0], size=5):\n",
    "    plot_voxel(X_test[rdn, ...])\n",
    "    plot_voxel(np.round(gamma_pred[rdn, :, :, :, 0]))\n",
    "    plot_voxel(np.round(np.abs(gamma_pred[rdn, :, :, :, 0])))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a713b-cd6a-4810-8c10-1cbbab04f9ce",
   "metadata": {},
   "source": [
    "## *ii)* Load the Mapper $\\Xi$ and the material classification network $\\Upsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc718c-46de-43b9-a81e-bcf227d89b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0063cae6-c99d-43e4-8690-80abc4e9fa7b",
   "metadata": {},
   "source": [
    "## *iii)* Setup the final reconstruction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4d70a-9318-4f4f-b9c3-69b73f2ad869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-TF_2_12",
   "language": "python",
   "name": "ml-tf_2_12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
